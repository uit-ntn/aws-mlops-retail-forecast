---
title: "Cost Management & Teardown"
date: 2024-01-01T00:00:00Z
weight: 14
chapter: false
pre: "<b>14. </b>"
---

{{% notice info %}}
**üéØ M·ª•c ti√™u Task 15:**

Qu·∫£n l√Ω v√† t·ªëi ∆∞u chi ph√≠ v·∫≠n h√†nh to√†n b·ªô h·∫° t·∫ßng MLOps tr√™n AWS:

- Gi·∫£m thi·ªÉu chi ph√≠ compute (EC2, SageMaker, ALB)
- T·ª± ƒë·ªông scale-down ho·∫∑c x√≥a t√†i nguy√™n kh√¥ng s·ª≠ d·ª•ng
- √Åp d·ª•ng lifecycle policies cho d·ªØ li·ªáu v√† container images
- ƒê·∫£m b·∫£o pipeline v·ª´a ho·∫°t ƒë·ªông hi·ªáu qu·∫£, v·ª´a ti·∫øt ki·ªám chi ph√≠ t·ªëi ƒëa
{{% /notice %}}

## 1. Chi ph√≠ v·∫≠n h√†nh h·ªá th·ªëng MLOps

Khi tri·ªÉn khai h·ªá th·ªëng MLOps ƒë·∫ßy ƒë·ªß nh∆∞ Retail Prediction API, chi ph√≠ v·∫≠n h√†nh c√≥ th·ªÉ nhanh ch√≥ng tƒÉng cao n·∫øu kh√¥ng ƒë∆∞·ª£c qu·∫£n l√Ω h·ª£p l√Ω. C√°c th√†nh ph·∫ßn ch√≠nh g√≥p ph·∫ßn v√†o chi ph√≠ bao g·ªìm:

{{< mermaid >}}
pie title Chi ph√≠ v·∫≠n h√†nh MLOps theo d·ªãch v·ª• (∆∞·ªõc t√≠nh)
    "EKS (EC2 + Control Plane)" : 40
    "SageMaker" : 25
    "S3 Storage" : 15
    "ALB & Network" : 10
    "CloudWatch & Logs" : 5
    "ECR & Kh√°c" : 5
{{< /mermaid >}}

### 1.1. Ph√¢n t√≠ch chi ph√≠ theo th√†nh ph·∫ßn

| D·ªãch v·ª• | Chi ph√≠ kh√¥ng t·ªëi ∆∞u | Nguy√™n nh√¢n | Gi·∫£i ph√°p |
|---------|---------------------|------------|-----------|
| **EKS NodeGroup** | 0.04 USD/gi·ªù/node | On-demand instances ch·∫°y 24/7 | Spot instances + Auto scaling + Schedule |
| **SageMaker Training** | 0.3 USD/job | Instances size l·ªõn, ch·∫°y l√¢u | Spot training + Hyperparameter tuning t·ªëi ∆∞u |
| **S3 Storage** | 0.023 USD/GB/th√°ng | L∆∞u tr·ªØ t·∫•t c·∫£ d·ªØ li·ªáu ·ªü Standard tier | Lifecycle policy + Intelligent-Tiering |
| **CloudWatch Logs** | 0.50 USD/GB | L∆∞u tr·ªØ logs kh√¥ng gi·ªõi h·∫°n | Log retention policy + Insights query t·ªëi ∆∞u |
| **ALB** | 0.027 USD/gi·ªù | Ch·∫°y li√™n t·ª•c k·ªÉ c·∫£ khi kh√¥ng c√≥ traffic | Schedule shutdown khi kh√¥ng s·ª≠ d·ª•ng |
| **ECR Storage** | 0.10 USD/GB/th√°ng | L∆∞u tr·ªØ t·∫•t c·∫£ image versions | Lifecycle policy x√≥a image c≈© |

## 2. S·ª≠ d·ª•ng EC2 Spot Instance

EC2 Spot Instances l√† m·ªôt trong nh·ªØng c√°ch hi·ªáu qu·∫£ nh·∫•t ƒë·ªÉ ti·∫øt ki·ªám chi ph√≠ compute tr√™n AWS, v·ªõi m·ª©c gi·∫£m l√™n ƒë·∫øn 70-90% so v·ªõi On-demand instances.

### 2.1. S·ª≠ d·ª•ng Spot cho EKS NodeGroup

C·∫≠p nh·∫≠t file c·∫•u h√¨nh Terraform cho EKS NodeGroup:

```hcl
module "eks_managed_node_group" {
  source = "terraform-aws-modules/eks/aws//modules/eks-managed-node-group"
  
  name            = "retail-forecast-nodes"
  cluster_name    = module.eks.cluster_name
  cluster_version = module.eks.cluster_version
  
  # C·∫•u h√¨nh Spot Instance
  capacity_type   = "SPOT"  # Thay v√¨ ON_DEMAND
  
  # Diversify instance types ƒë·ªÉ tƒÉng kh·∫£ nƒÉng c√≥ Spot
  instance_types  = ["t3.medium", "t3a.medium", "t2.medium"]
  
  min_size        = 2
  max_size        = 5
  desired_size    = 2
  
  # Th√™m labels v√† taints cho Kubernetes scheduler
  labels = {
    Environment = "dev"
    GithubRepo = "retail-forecast"
    GithubOrg  = "terraform-aws-modules"
    Spot       = "true"
  }
  
  tags = {
    Environment = "dev"
    Terraform   = "true"
    CostCenter  = "retail-forecast"
  }
}
```

### 2.2. S·ª≠ d·ª•ng Spot cho SageMaker Training

Update script t·∫°o SageMaker training job ƒë·ªÉ s·ª≠ d·ª•ng spot instances:

```python
# aws/script/create_training_job.py

import boto3
import argparse
import time

def create_training_job(job_name, data_bucket, output_bucket, instance_type, use_spot=True):
    sagemaker = boto3.client('sagemaker')
    
    # T√≠nh to√°n th·ªùi gian stop cho Spot (gi·ªõi h·∫°n 1 gi·ªù)
    current_time = int(time.time())
    stop_time = current_time + 3600  # 1 hour
    
    # C·∫•u h√¨nh training job
    training_params = {
        'TrainingJobName': job_name,
        'AlgorithmSpecification': {
            'TrainingImage': '123456789012.dkr.ecr.us-east-1.amazonaws.com/retail-forecast-training:latest',
            'TrainingInputMode': 'File'
        },
        'RoleArn': 'arn:aws:iam::123456789012:role/SageMakerExecutionRole',
        'InputDataConfig': [
            {
                'ChannelName': 'train',
                'DataSource': {
                    'S3DataSource': {
                        'S3DataType': 'S3Prefix',
                        'S3Uri': f's3://{data_bucket}/train',
                        'S3DataDistributionType': 'FullyReplicated'
                    }
                }
            }
        ],
        'OutputDataConfig': {
            'S3OutputPath': f's3://{output_bucket}/output'
        },
        'ResourceConfig': {
            'InstanceType': instance_type,
            'InstanceCount': 1,
            'VolumeSizeInGB': 10
        },
        'StoppingCondition': {
            'MaxRuntimeInSeconds': 3600
        },
        'Tags': [
            {
                'Key': 'Project',
                'Value': 'RetailForecast'
            }
        ]
    }
    
    # C·∫•u h√¨nh Spot training n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
    if use_spot:
        training_params['EnableManagedSpotTraining'] = True
        training_params['StoppingCondition']['MaxWaitTimeInSeconds'] = 3900  # Th√™m th·ªùi gian ch·ªù t·ªëi ƒëa
    
    response = sagemaker.create_training_job(**training_params)
    return response

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--job-name', type=str, required=True)
    parser.add_argument('--data-bucket', type=str, required=True)
    parser.add_argument('--output-bucket', type=str, required=True)
    parser.add_argument('--instance-type', type=str, default='ml.m5.large')
    parser.add_argument('--use-spot', type=bool, default=True)
    
    args = parser.parse_args()
    
    response = create_training_job(
        args.job_name,
        args.data_bucket,
        args.output_bucket,
        args.instance_type,
        args.use_spot
    )
    
    print(f"Training job created: {response['TrainingJobArn']}")
```

### 2.3. X·ª≠ l√Ω gi√°n ƒëo·∫°n Spot Instance

ƒê·ªÉ ƒë·∫£m b·∫£o h·ªá th·ªëng v·∫´n ho·∫°t ƒë·ªông khi c√°c Spot Instances b·ªã thu h·ªìi, c·∫ßn c·∫•u h√¨nh:

1. **Pod Disruption Budget (PDB)** ƒë·ªÉ ƒë·∫£m b·∫£o s·ªë l∆∞·ª£ng pod t·ªëi thi·ªÉu:

```yaml
# aws/k8s/pdb/retail-forecast-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: retail-forecast-pdb
  namespace: retail-forecast
spec:
  minAvailable: 1  # Lu√¥n ƒë·∫£m b·∫£o √≠t nh·∫•t 1 pod ƒëang ch·∫°y
  selector:
    matchLabels:
      app: retail-forecast-api
```

2. **Cluster Autoscaler** v·ªõi Spot Instance Handling:

```yaml
# aws/k8s/addons/cluster-autoscaler.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      containers:
        - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.26.2
          name: cluster-autoscaler
          command:
            - ./cluster-autoscaler
            - --v=4
            - --stderrthreshold=info
            - --cloud-provider=aws
            - --skip-nodes-with-local-storage=false
            - --expander=least-waste
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/retail-forecast-cluster
            - --balance-similar-node-groups
            - --skip-nodes-with-system-pods=false
          volumeMounts:
            - name: ssl-certs
              mountPath: /etc/ssl/certs/ca-certificates.crt
              readOnly: true
      volumes:
        - name: ssl-certs
          hostPath:
            path: "/etc/ssl/certs/ca-bundle.crt"
```

## 3. S3 Lifecycle & Intelligent-Tiering

### 3.1. C·∫•u h√¨nh Lifecycle Policy cho S3 Bucket

Tri·ªÉn khai lifecycle policy th√¥ng qua Terraform:

```hcl
# infra/modules/s3/main.tf
resource "aws_s3_bucket" "retail_forecast_data" {
  bucket = "retail-forecast-data-${var.environment}"
  
  tags = {
    Name        = "Retail Forecast Data"
    Environment = var.environment
    Project     = "RetailForecast"
  }
}

# Lifecycle configuration
resource "aws_s3_bucket_lifecycle_configuration" "data_lifecycle" {
  bucket = aws_s3_bucket.retail_forecast_data.id

  rule {
    id     = "raw-data-tier"
    status = "Enabled"
    
    filter {
      prefix = "raw/"
    }

    transition {
      days          = 30
      storage_class = "INTELLIGENT_TIERING"
    }
  }
  
  rule {
    id     = "silver-data-tier"
    status = "Enabled"
    
    filter {
      prefix = "silver/"
    }

    transition {
      days          = 30
      storage_class = "INTELLIGENT_TIERING"
    }
  }
  
  rule {
    id     = "artifacts-archive"
    status = "Enabled"
    
    filter {
      prefix = "artifacts/"
    }

    transition {
      days          = 90
      storage_class = "GLACIER_IR"
    }
    
    transition {
      days          = 180
      storage_class = "DEEP_ARCHIVE"
    }
  }
  
  rule {
    id     = "logs-archive"
    status = "Enabled"
    
    filter {
      prefix = "logs/"
    }

    transition {
      days          = 90
      storage_class = "GLACIER_IR"
    }
    
    transition {
      days          = 180
      storage_class = "DEEP_ARCHIVE"
    }
  }
  
  rule {
    id     = "temp-cleanup"
    status = "Enabled"
    
    filter {
      and {
        prefix = "tmp/"
        tag {
          key   = "temporary"
          value = "true"
        }
      }
    }
    
    expiration {
      days = 7
    }
  }
}
```

### 3.2. C·∫•u h√¨nh Intelligent-Tiering

```hcl
# infra/modules/s3/intelligent_tiering.tf
resource "aws_s3_bucket_intelligent_tiering_configuration" "retail_data_tiering" {
  bucket = aws_s3_bucket.retail_forecast_data.id
  name   = "RetailDataTiering"
  
  tiering {
    access_tier = "ARCHIVE_ACCESS"
    days        = 90
  }
  
  tiering {
    access_tier = "DEEP_ARCHIVE_ACCESS"
    days        = 180
  }
  
  filter {
    prefix = "data/"
  }
}
```

## 4. T·ª± ƒë·ªông d·ª´ng t√†i nguy√™n ngo√†i gi·ªù

### 4.1. Schedule Lambda v·ªõi EventBridge

T·∫°o Lambda function ƒë·ªÉ stop/start t√†i nguy√™n:

```python
# aws/scripts/resource_scheduler.py
import boto3
import os

def lambda_handler(event, context):
    action = event.get('action', 'stop')  # 'stop' or 'start'
    
    # EKS NodeGroup scaling
    eks = boto3.client('eks')
    autoscaling = boto3.client('autoscaling')
    
    cluster_name = os.environ.get('EKS_CLUSTER_NAME', 'retail-forecast-cluster')
    nodegroup_name = os.environ.get('NODEGROUP_NAME', 'retail-forecast-nodes')
    
    if action == 'stop':
        # Scale down to 0
        print(f"Scaling down nodegroup {nodegroup_name} in cluster {cluster_name}")
        
        # L·∫•y auto scaling group name t·ª´ nodegroup
        response = eks.describe_nodegroup(
            clusterName=cluster_name,
            nodegroupName=nodegroup_name
        )
        
        asg_name = response['nodegroup']['resources']['autoScalingGroups'][0]['name']
        
        # Scale down ASG v·ªÅ 0
        autoscaling.update_auto_scaling_group(
            AutoScalingGroupName=asg_name,
            MinSize=0,
            DesiredCapacity=0
        )
        
        print(f"NodeGroup {nodegroup_name} scaled down to 0")
    
    elif action == 'start':
        # Scale up to desired capacity
        print(f"Scaling up nodegroup {nodegroup_name} in cluster {cluster_name}")
        
        response = eks.describe_nodegroup(
            clusterName=cluster_name,
            nodegroupName=nodegroup_name
        )
        
        asg_name = response['nodegroup']['resources']['autoScalingGroups'][0]['name']
        
        # Scale up ASG to desired capacity
        autoscaling.update_auto_scaling_group(
            AutoScalingGroupName=asg_name,
            MinSize=2,
            DesiredCapacity=2
        )
        
        print(f"NodeGroup {nodegroup_name} scaled up to 2")
    
    # SageMaker Endpoint
    if os.environ.get('SAGEMAKER_ENDPOINT'):
        sm_client = boto3.client('sagemaker')
        endpoint_name = os.environ.get('SAGEMAKER_ENDPOINT')
        
        if action == 'stop':
            # Endpoint kh√¥ng th·ªÉ d·ª´ng nh∆∞ng c√≥ th·ªÉ x√≥a v√† t·∫°o l·∫°i sau
            print(f"Deleting SageMaker endpoint {endpoint_name}")
            try:
                sm_client.delete_endpoint(EndpointName=endpoint_name)
                print(f"Endpoint {endpoint_name} deleted")
            except Exception as e:
                print(f"Error deleting endpoint: {e}")
        
    return {
        'statusCode': 200,
        'body': f"Successfully executed {action} action"
    }
```

Terraform ƒë·ªÉ t·∫°o EventBridge schedule v√† Lambda:

```hcl
# infra/modules/scheduler/main.tf

resource "aws_lambda_function" "resource_scheduler" {
  function_name = "retail-forecast-resource-scheduler"
  handler       = "resource_scheduler.lambda_handler"
  runtime       = "python3.9"
  role          = aws_iam_role.lambda_role.arn
  filename      = "resource_scheduler.zip"
  timeout       = 300
  
  environment {
    variables = {
      EKS_CLUSTER_NAME   = var.eks_cluster_name
      NODEGROUP_NAME     = var.nodegroup_name
      SAGEMAKER_ENDPOINT = var.sagemaker_endpoint
    }
  }
}

# T·∫°o EventBridge rule ƒë·ªÉ d·ª´ng t√†i nguy√™n l√∫c 19:00 UTC
resource "aws_cloudwatch_event_rule" "stop_resources" {
  name                = "retail-forecast-stop-resources"
  description         = "Stop resources at 19:00 UTC"
  schedule_expression = "cron(0 19 * * ? *)"
}

# G·∫Øn Lambda v·ªõi rule stop
resource "aws_cloudwatch_event_target" "stop_resources_target" {
  rule      = aws_cloudwatch_event_rule.stop_resources.name
  target_id = "RetailForecastStopResources"
  arn       = aws_lambda_function.resource_scheduler.arn
  input     = jsonencode({
    action = "stop"
  })
}

# T·∫°o EventBridge rule ƒë·ªÉ kh·ªüi ƒë·ªông t√†i nguy√™n l√∫c 7:00 UTC
resource "aws_cloudwatch_event_rule" "start_resources" {
  name                = "retail-forecast-start-resources"
  description         = "Start resources at 7:00 UTC"
  schedule_expression = "cron(0 7 * * ? *)"
}

# G·∫Øn Lambda v·ªõi rule start
resource "aws_cloudwatch_event_target" "start_resources_target" {
  rule      = aws_cloudwatch_event_rule.start_resources.name
  target_id = "RetailForecastStartResources"
  arn       = aws_lambda_function.resource_scheduler.arn
  input     = jsonencode({
    action = "start"
  })
}

# C·∫•p quy·ªÅn cho EventBridge ƒë·ªÉ g·ªçi Lambda
resource "aws_lambda_permission" "allow_eventbridge_stop" {
  statement_id  = "AllowExecutionFromEventBridgeStop"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.resource_scheduler.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.stop_resources.arn
}

resource "aws_lambda_permission" "allow_eventbridge_start" {
  statement_id  = "AllowExecutionFromEventBridgeStart"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.resource_scheduler.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.start_resources.arn
}
```

### 4.2. Terraform Destroy cho CI/CD Pipeline

Th√™m job v√†o GitHub Actions workflow ƒë·ªÉ x√≥a to√†n b·ªô t√†i nguy√™n sau khi ho√†n th√†nh:

```yaml
# .github/workflows/mlops-pipeline.yml
jobs:
  # C√°c job hi·ªán t·∫°i...
  
  terraform_destroy:
    name: Destroy Infrastructure
    runs-on: ubuntu-latest
    needs: [deploy_eks, monitoring]
    if: github.event.inputs.destroy_after_demo == 'true'
    environment: 
      name: ${{ needs.setup.outputs.environment }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsRole
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
    
    - name: Terraform Init
      run: |
        cd aws/infra
        terraform init
    
    - name: Terraform Destroy
      run: |
        cd aws/infra
        terraform destroy -auto-approve
```

## 5. Cost Visibility & Alerts

### 5.1. Tag Strategy cho AWS Resources

```hcl
# Th√™m v√†o t·∫•t c·∫£ resource modules

locals {
  common_tags = {
    Project     = "RetailForecastMLOps"
    Environment = var.environment
    Terraform   = "true"
    CostCenter  = "DataScience"
    Team        = "MLOps"
  }
}

# √Åp d·ª•ng tag v√†o t·∫•t c·∫£ resource
```

### 5.2. AWS Budgets Alert

```hcl
# infra/modules/budget/main.tf
resource "aws_budgets_budget" "cost" {
  name              = "retail-forecast-${var.environment}-monthly-budget"
  budget_type       = "COST"
  limit_amount      = var.monthly_limit
  limit_unit        = "USD"
  time_unit         = "MONTHLY"
  time_period_start = "2023-01-01_00:00"
  
  cost_filter {
    name = "TagKeyValue"
    values = [
      "user:Project$RetailForecastMLOps"
    ]
  }
  
  notification {
    comparison_operator        = "GREATER_THAN"
    threshold                  = 80
    threshold_type             = "PERCENTAGE"
    notification_type          = "ACTUAL"
    subscriber_email_addresses = var.notification_emails
  }
  
  notification {
    comparison_operator        = "GREATER_THAN"
    threshold                  = 100
    threshold_type             = "PERCENTAGE"
    notification_type          = "ACTUAL"
    subscriber_email_addresses = var.notification_emails
    subscriber_sns_topic_arns  = [var.sns_topic_arn]
  }
}
```

Script ƒë·ªÉ t·∫°o AWS Budget qua CLI:

```bash
# aws/scripts/create_budget.sh
#!/bin/bash

ACCOUNT_ID=$(aws sts get-caller-identity --query "Account" --output text)
EMAIL="your-email@example.com"
BUDGET_NAME="MLOpsBudget"
BUDGET_LIMIT=5 # USD

# T·∫°o AWS Budget
aws budgets create-budget \
  --account-id $ACCOUNT_ID \
  --budget '{ 
    "BudgetName": "'$BUDGET_NAME'", 
    "BudgetLimit": { 
      "Amount": "'$BUDGET_LIMIT'", 
      "Unit": "USD" 
    },
    "CostFilters": {
      "TagKeyValue": [
        "user:Project$RetailForecastMLOps"
      ]
    },
    "BudgetType": "COST", 
    "TimeUnit": "MONTHLY" 
  }' \
  --notifications-with-subscribers '[
    {
      "Notification": { 
        "NotificationType": "ACTUAL", 
        "ComparisonOperator": "GREATER_THAN", 
        "Threshold": 80, 
        "ThresholdType": "PERCENTAGE" 
      },
      "Subscribers": [
        { 
          "SubscriptionType": "EMAIL", 
          "Address": "'$EMAIL'" 
        }
      ]
    },
    {
      "Notification": { 
        "NotificationType": "ACTUAL", 
        "ComparisonOperator": "GREATER_THAN", 
        "Threshold": 100,
        "ThresholdType": "PERCENTAGE" 
      },
      "Subscribers": [
        { 
          "SubscriptionType": "EMAIL", 
          "Address": "'$EMAIL'" 
        }
      ]
    }
  ]'
```

## 6. ECR & CloudWatch Optimization

### 6.1. ECR Lifecycle Policy

```hcl
# infra/modules/ecr/main.tf
resource "aws_ecr_repository" "retail_forecast" {
  name                 = "retail-forecast"
  image_tag_mutability = "MUTABLE"
  
  image_scanning_configuration {
    scan_on_push = true
  }
  
  tags = local.common_tags
}

resource "aws_ecr_lifecycle_policy" "retail_forecast_policy" {
  repository = aws_ecr_repository.retail_forecast.name
  
  policy = jsonencode({
    rules = [
      {
        rulePriority = 1,
        description  = "Keep only 3 latest untagged images",
        selection = {
          tagStatus     = "untagged",
          countType     = "imageCountMoreThan",
          countNumber   = 3
        },
        action = {
          type = "expire"
        }
      },
      {
        rulePriority = 2,
        description  = "Keep only 3 latest images per tag prefix",
        selection = {
          tagStatus     = "tagged",
          tagPrefixList = ["prod", "stage", "dev"],
          countType     = "imageCountMoreThan",
          countNumber   = 3
        },
        action = {
          type = "expire"
        }
      },
      {
        rulePriority = 3,
        description  = "Keep only the 10 most recent images",
        selection = {
          tagStatus   = "any",
          countType   = "imageCountMoreThan",
          countNumber = 10
        },
        action = {
          type = "expire"
        }
      }
    ]
  })
}
```

Ho·∫∑c s·ª≠ d·ª•ng AWS CLI:

```bash
aws ecr put-lifecycle-policy \
  --repository-name retail-forecast \
  --lifecycle-policy-text '{
    "rules": [
        {
            "rulePriority": 1,
            "description": "Keep only 3 latest untagged images",
            "selection": {
                "tagStatus": "untagged",
                "countType": "imageCountMoreThan",
                "countNumber": 3
            },
            "action": {
                "type": "expire"
            }
        },
        {
            "rulePriority": 2,
            "description": "Keep only 3 latest images per tag prefix",
            "selection": {
                "tagStatus": "tagged",
                "tagPrefixList": ["prod", "stage", "dev"],
                "countType": "imageCountMoreThan",
                "countNumber": 3
            },
            "action": {
                "type": "expire"
            }
        },
        {
            "rulePriority": 3,
            "description": "Keep only the 10 most recent images",
            "selection": {
                "tagStatus": "any",
                "countType": "imageCountMoreThan",
                "countNumber": 10
            },
            "action": {
                "type": "expire"
            }
        }
    ]
}'
```

### 6.2. CloudWatch Log Retention Policy

```hcl
# infra/modules/logs/main.tf
resource "aws_cloudwatch_log_group" "eks_logs" {
  name              = "/aws/eks/retail-forecast-cluster/cluster"
  retention_in_days = 30
  
  tags = local.common_tags
}

resource "aws_cloudwatch_log_group" "app_logs" {
  name              = "/aws/retail-forecast/api"
  retention_in_days = 30
  
  tags = local.common_tags
}

resource "aws_cloudwatch_log_group" "sagemaker_training" {
  name              = "/aws/sagemaker/TrainingJobs"
  retention_in_days = 30
  
  tags = local.common_tags
}
```

Ho·∫∑c s·ª≠ d·ª•ng AWS CLI:

```bash
# ƒê·∫∑t retention policy cho CloudWatch Logs
aws logs put-retention-policy \
  --log-group-name "/aws/eks/retail-forecast-cluster/cluster" \
  --retention-in-days 30

aws logs put-retention-policy \
  --log-group-name "/aws/retail-forecast/api" \
  --retention-in-days 30

aws logs put-retention-policy \
  --log-group-name "/aws/sagemaker/TrainingJobs" \
  --retention-in-days 30
```

## 7. T·ª± ƒë·ªông Teardown to√†n b·ªô h·∫° t·∫ßng

### 7.1. Script Terraform Destroy

```bash
# aws/scripts/teardown.sh
#!/bin/bash

set -e

echo "Starting teardown of retail-forecast MLOps infrastructure..."

# 1. X√≥a c√°c t√†i nguy√™n Kubernetes tr∆∞·ªõc
echo "Deleting Kubernetes resources..."
kubectl delete namespace retail-forecast --ignore-not-found=true

# 2. X√≥a SageMaker Endpoints
echo "Deleting SageMaker endpoints..."
ENDPOINTS=$(aws sagemaker list-endpoints --name-contains retail-forecast --query "Endpoints[].EndpointName" --output text)
if [ ! -z "$ENDPOINTS" ]; then
  for ENDPOINT in $ENDPOINTS; do
    echo "Deleting endpoint: $ENDPOINT"
    aws sagemaker delete-endpoint --endpoint-name $ENDPOINT
  done
fi

# 3. Th·ª±c hi·ªán terraform destroy
echo "Running Terraform destroy..."
cd ../infra
terraform init
terraform destroy -auto-approve

echo "Teardown completed successfully!"
```

### 7.2. Th√™m v√†o GitHub Actions Workflow

```yaml
# .github/workflows/teardown.yml
name: MLOps Infrastructure Teardown

on:
  workflow_dispatch:
    inputs:
      confirmation:
        description: 'Type "destroy" to confirm deletion of all resources'
        required: true
        
env:
  AWS_REGION: us-east-1
  TF_VAR_environment: dev

jobs:
  teardown:
    name: Teardown Infrastructure
    runs-on: ubuntu-latest
    if: github.event.inputs.confirmation == 'destroy'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsRole
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Setup kubectl
      uses: azure/setup-kubectl@v3
    
    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --name retail-forecast-cluster --region ${{ env.AWS_REGION }}
    
    - name: Delete Kubernetes resources
      run: |
        kubectl delete namespace retail-forecast --ignore-not-found=true
    
    - name: Delete SageMaker endpoints
      run: |
        ENDPOINTS=$(aws sagemaker list-endpoints --name-contains retail-forecast --query "Endpoints[].EndpointName" --output text)
        if [ ! -z "$ENDPOINTS" ]; then
          for ENDPOINT in $ENDPOINTS; do
            echo "Deleting endpoint: $ENDPOINT"
            aws sagemaker delete-endpoint --endpoint-name $ENDPOINT
          done
        fi
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
    
    - name: Terraform Init
      run: |
        cd aws/infra
        terraform init
    
    - name: Terraform Destroy
      run: |
        cd aws/infra
        terraform destroy -auto-approve
    
    - name: Send notification
      if: always()
      run: |
        if [ "${{ job.status }}" == "success" ]; then
          MESSAGE="‚úÖ Infrastructure teardown completed successfully"
        else
          MESSAGE="‚ùå Infrastructure teardown failed"
        fi
        
        aws sns publish \
          --topic-arn ${{ secrets.SNS_TOPIC_ARN }} \
          --subject "MLOps Infrastructure Teardown" \
          --message "$MESSAGE"
```

## 8. Chi ph√≠ ∆∞·ªõc t√≠nh sau khi t·ªëi ∆∞u

D∆∞·ªõi ƒë√¢y l√† chi ph√≠ d·ª± ki·∫øn sau khi √°p d·ª•ng c√°c bi·ªán ph√°p t·ªëi ∆∞u:

{{< mermaid >}}
gantt
    title Chi ph√≠ MLOps - Tr∆∞·ªõc v√† Sau T·ªëi ∆∞u
    dateFormat  YYYY-MM-DD
    section EKS NodeGroup
    Tr∆∞·ªõc t·ªëi ∆∞u      :done, 2023-01-01, 30d
    Sau t·ªëi ∆∞u (Spot)   :active, 2023-01-01, 30d
    section SageMaker Training
    Tr∆∞·ªõc t·ªëi ∆∞u      :done, 2023-01-01, 30d
    Sau t·ªëi ∆∞u (Spot)   :active, 2023-01-01, 30d
    section S3 Storage
    Tr∆∞·ªõc t·ªëi ∆∞u      :done, 2023-01-01, 30d
    Sau t·ªëi ∆∞u (Tiering)   :active, 2023-01-01, 30d
    section CloudWatch
    Tr∆∞·ªõc t·ªëi ∆∞u      :done, 2023-01-01, 30d
    Sau t·ªëi ∆∞u (Retention)   :active, 2023-01-01, 30d
{{< /mermaid >}}

| Th√†nh ph·∫ßn | Tr∆∞·ªõc t·ªëi ∆∞u | Sau t·ªëi ∆∞u | Ti·∫øt ki·ªám (%) |
|------------|--------------|------------|---------------|
| EKS NodeGroup | 0.04 USD/h √ó 24h √ó 30d = 28.80 USD | 0.012 USD/h √ó 10h √ó 20d = 2.40 USD | 92% |
| SageMaker Training | 0.30 USD/job √ó 30 = 9.00 USD | 0.09 USD/job √ó 30 = 2.70 USD | 70% |
| S3 Storage (50GB) | 0.023 USD/GB √ó 50 = 1.15 USD | 0.0125 USD/GB √ó 50 = 0.625 USD | 46% |
| CloudWatch Logs (5GB) | 0.50 USD/GB √ó 5 = 2.50 USD | 0.50 USD/GB √ó 1.5 = 0.75 USD | 70% |
| ALB | 0.027 USD/h √ó 24h √ó 30d = 19.44 USD | 0.027 USD/h √ó 10h √ó 20d = 5.40 USD | 72% |
| ECR Storage (5GB) | 0.10 USD/GB √ó 5 = 0.50 USD | 0.10 USD/GB √ó 2 = 0.20 USD | 60% |
| **T·ªïng chi ph√≠ (1 th√°ng)** | **~61.39 USD** | **~12.08 USD** | **80%** |

### Chi ph√≠ h√†ng th√°ng

{{< mermaid >}}
pie title Chi ph√≠ h√†ng th√°ng sau t·ªëi ∆∞u
    "EKS NodeGroup" : 2.40
    "SageMaker Training" : 2.70
    "S3 Storage" : 0.63
    "CloudWatch Logs" : 0.75
    "ALB" : 5.40
    "ECR Storage" : 0.20
{{< /mermaid >}}

## 9. K·∫øt qu·∫£ k·ª≥ v·ªçng

### ‚úÖ Checklist Ho√†n th√†nh

- [ ] **EC2 Spot Instance**: C·∫•u h√¨nh EKS NodeGroup v√† SageMaker s·ª≠ d·ª•ng Spot
- [ ] **S3 Lifecycle**: Tri·ªÉn khai lifecycle policies cho data v√† artifacts
- [ ] **Auto Schedule**: Lambda + EventBridge ƒë·ªÉ t·ª± ƒë·ªông d·ª´ng/kh·ªüi ƒë·ªông t√†i nguy√™n
- [ ] **Budget Alert**: Thi·∫øt l·∫≠p gi√°m s√°t chi ph√≠ v√† c·∫£nh b√°o
- [ ] **ECR Lifecycle**: Ch·ªâ gi·ªØ l·∫°i 3 phi√™n b·∫£n image m·ªõi nh·∫•t
- [ ] **Log Retention**: CloudWatch logs retention policy 30 ng√†y
- [ ] **Complete Teardown**: Script ƒë·ªÉ x√≥a ho√†n to√†n t√†i nguy√™n sau demo

### üìä Verification Steps

```bash
# 1. Ki·ªÉm tra EKS NodeGroup ƒëang s·ª≠ d·ª•ng Spot
aws eks describe-nodegroup \
  --cluster-name retail-forecast-cluster \
  --nodegroup-name retail-forecast-nodes \
  --query 'nodegroup.capacityType'

# 2. Ki·ªÉm tra S3 lifecycle policy
aws s3api get-bucket-lifecycle-configuration \
  --bucket retail-forecast-data-dev

# 3. Ki·ªÉm tra CloudWatch logs retention
aws logs describe-log-groups \
  --log-group-name-prefix /aws/retail-forecast \
  --query 'logGroups[*].[logGroupName,retentionInDays]'

# 4. Ki·ªÉm tra ECR lifecycle policy
aws ecr get-lifecycle-policy \
  --repository-name retail-forecast

# 5. Ki·ªÉm tra AWS Budget ƒë√£ ƒë∆∞·ª£c t·∫°o
aws budgets describe-budgets \
  --account-id $(aws sts get-caller-identity --query "Account" --output text)

# 6. Th·ª±c hi·ªán teardown v√† ki·ªÉm tra x√≥a s·∫°ch
cd aws/scripts
./teardown.sh

# Ki·ªÉm tra kh√¥ng c√≤n resources
aws eks list-clusters --query 'clusters[*]' | grep retail
aws s3 ls | grep retail-forecast
aws ecr describe-repositories --query 'repositories[*].repositoryName' | grep retail
aws sagemaker list-endpoints --query 'Endpoints[*].EndpointName' | grep retail
```

## T·ªïng k·∫øt

Qu·∫£n l√Ω chi ph√≠ hi·ªáu qu·∫£ l√† m·ªôt trong nh·ªØng kh√≠a c·∫°nh quan tr·ªçng nh·∫•t c·ªßa MLOps tr√™n AWS. B·∫±ng vi·ªác √°p d·ª•ng c√°c chi·∫øn l∆∞·ª£c t·ªëi ∆∞u nh∆∞ Spot Instances, S3 lifecycle policies, auto scheduling, v√† resource cleanup, ch√∫ng ta c√≥ th·ªÉ gi·∫£m chi ph√≠ v·∫≠n h√†nh ƒë·∫øn 80% m√† v·∫´n duy tr√¨ ƒë∆∞·ª£c kh·∫£ nƒÉng m·ªü r·ªông v√† hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng.

C√°c bi·ªán ph√°p t·ªëi ∆∞u chi ph√≠ n√†y kh√¥ng ch·ªâ gi√∫p ti·∫øt ki·ªám ng√¢n s√°ch m√† c√≤n gi√∫p h·ªá th·ªëng MLOps ho·∫°t ƒë·ªông hi·ªáu qu·∫£ h∆°n th√¥ng qua vi·ªác t·ª± ƒë·ªông h√≥a qu·∫£n l√Ω t√†i nguy√™n, gi√°m s√°t chi ph√≠, v√† th·ª±c hi·ªán c√°c best practices trong qu·∫£n l√Ω v√≤ng ƒë·ªùi c·ªßa d·ªØ li·ªáu v√† container images.

**K·∫øt qu·∫£ ch√≠nh:**
- Ti·∫øt ki·ªám 80% chi ph√≠ v·∫≠n h√†nh (~12.08 USD/th√°ng so v·ªõi ~61.39 USD/th√°ng)
- T·ª± ƒë·ªông h√≥a vi·ªác qu·∫£n l√Ω t√†i nguy√™n theo l·ªãch tr√¨nh
- Chi·∫øn l∆∞·ª£c l∆∞u tr·ªØ d·ªØ li·ªáu t·ªëi ∆∞u v·ªõi lifecycle policies
- H·ªá th·ªëng gi√°m s√°t v√† c·∫£nh b√°o chi ph√≠ ch·ªß ƒë·ªông
- Kh·∫£ nƒÉng x√≥a ho√†n to√†n t√†i nguy√™n khi kh√¥ng s·ª≠ d·ª•ng

---

**Next Step**: Final Review & Submission